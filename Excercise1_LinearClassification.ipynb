{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex1-LinearClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoDCIAcT14Hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aefedbf9-c6e1-4668-9b13-9f7416f8e98e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oppfuF5r2uUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c36957e3-2799-4cda-e842-29541091f725"
      },
      "source": [
        "#Load the data set\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer_data = load_breast_cancer()\n",
        "\n",
        "#check the data type\n",
        "print(type(cancer_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZrjspOa6Jgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6cd52d4d-4d4c-48f0-fa2d-8590fae717a5"
      },
      "source": [
        "#Convert it to pandas data frame for ease of use\n",
        "import pandas as pd\n",
        "cancer_df = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
        "cancer_df['target'] = pd.Series(cancer_data.target)\n",
        "print(cancer_df.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   mean radius  mean texture  ...  worst fractal dimension  target\n",
            "0        17.99         10.38  ...                  0.11890       0\n",
            "1        20.57         17.77  ...                  0.08902       0\n",
            "2        19.69         21.25  ...                  0.08758       0\n",
            "3        11.42         20.38  ...                  0.17300       0\n",
            "4        20.29         14.34  ...                  0.07678       0\n",
            "\n",
            "[5 rows x 31 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aop-rcB0666O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "a7dc1d0e-827d-4514-92ae-e5c578949d77"
      },
      "source": [
        "#check out the head to understand the data\n",
        "cancer_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "3        11.42         20.38  ...                  0.17300       0\n",
              "4        20.29         14.34  ...                  0.07678       0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnpNUpQw7kQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "e8954a8a-aa89-4944-92f2-de2c8625621f"
      },
      "source": [
        "#understand the dimension and the data types\n",
        "cancer_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoHNKYux7oPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the shape elements\n",
        "N, D = cancer_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXhSKQTB9Q8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6133a934-11f2-4c66-ae7a-90359c80ebcb"
      },
      "source": [
        "#split the data set \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer_df.drop(['target'],axis=1), cancer_df['target'], test_size=0.3, random_state=23)\n",
        "\n",
        "#check the split\n",
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326    1\n",
              "13     0\n",
              "38     0\n",
              "135    0\n",
              "492    0\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c25fMoI_OQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "598a1e13-a3d2-46cd-ac60-8f6211ccc10c"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>14.11</td>\n",
              "      <td>12.88</td>\n",
              "      <td>90.03</td>\n",
              "      <td>616.5</td>\n",
              "      <td>0.09309</td>\n",
              "      <td>0.05306</td>\n",
              "      <td>0.01765</td>\n",
              "      <td>0.02733</td>\n",
              "      <td>0.1373</td>\n",
              "      <td>0.05700</td>\n",
              "      <td>0.2571</td>\n",
              "      <td>1.081</td>\n",
              "      <td>1.558</td>\n",
              "      <td>23.92</td>\n",
              "      <td>0.006692</td>\n",
              "      <td>0.01132</td>\n",
              "      <td>0.005717</td>\n",
              "      <td>0.006627</td>\n",
              "      <td>0.014160</td>\n",
              "      <td>0.002476</td>\n",
              "      <td>15.53</td>\n",
              "      <td>18.00</td>\n",
              "      <td>98.40</td>\n",
              "      <td>749.9</td>\n",
              "      <td>0.12810</td>\n",
              "      <td>0.11090</td>\n",
              "      <td>0.05307</td>\n",
              "      <td>0.05890</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>0.07083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15.85</td>\n",
              "      <td>23.95</td>\n",
              "      <td>103.70</td>\n",
              "      <td>782.7</td>\n",
              "      <td>0.08401</td>\n",
              "      <td>0.10020</td>\n",
              "      <td>0.09938</td>\n",
              "      <td>0.05364</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.05338</td>\n",
              "      <td>0.4033</td>\n",
              "      <td>1.078</td>\n",
              "      <td>2.903</td>\n",
              "      <td>36.58</td>\n",
              "      <td>0.009769</td>\n",
              "      <td>0.03126</td>\n",
              "      <td>0.050510</td>\n",
              "      <td>0.019920</td>\n",
              "      <td>0.029810</td>\n",
              "      <td>0.003002</td>\n",
              "      <td>16.84</td>\n",
              "      <td>27.66</td>\n",
              "      <td>112.00</td>\n",
              "      <td>876.5</td>\n",
              "      <td>0.11310</td>\n",
              "      <td>0.19240</td>\n",
              "      <td>0.23220</td>\n",
              "      <td>0.11190</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.06287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>14.99</td>\n",
              "      <td>25.20</td>\n",
              "      <td>95.54</td>\n",
              "      <td>698.8</td>\n",
              "      <td>0.09387</td>\n",
              "      <td>0.05131</td>\n",
              "      <td>0.02398</td>\n",
              "      <td>0.02899</td>\n",
              "      <td>0.1565</td>\n",
              "      <td>0.05504</td>\n",
              "      <td>1.2140</td>\n",
              "      <td>2.188</td>\n",
              "      <td>8.077</td>\n",
              "      <td>106.00</td>\n",
              "      <td>0.006883</td>\n",
              "      <td>0.01094</td>\n",
              "      <td>0.018180</td>\n",
              "      <td>0.019170</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.001754</td>\n",
              "      <td>14.99</td>\n",
              "      <td>25.20</td>\n",
              "      <td>95.54</td>\n",
              "      <td>698.8</td>\n",
              "      <td>0.09387</td>\n",
              "      <td>0.05131</td>\n",
              "      <td>0.02398</td>\n",
              "      <td>0.02899</td>\n",
              "      <td>0.1565</td>\n",
              "      <td>0.05504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>12.77</td>\n",
              "      <td>22.47</td>\n",
              "      <td>81.72</td>\n",
              "      <td>506.3</td>\n",
              "      <td>0.09055</td>\n",
              "      <td>0.05761</td>\n",
              "      <td>0.04711</td>\n",
              "      <td>0.02704</td>\n",
              "      <td>0.1585</td>\n",
              "      <td>0.06065</td>\n",
              "      <td>0.2367</td>\n",
              "      <td>1.380</td>\n",
              "      <td>1.457</td>\n",
              "      <td>19.87</td>\n",
              "      <td>0.007499</td>\n",
              "      <td>0.01202</td>\n",
              "      <td>0.023320</td>\n",
              "      <td>0.008920</td>\n",
              "      <td>0.016470</td>\n",
              "      <td>0.002629</td>\n",
              "      <td>14.49</td>\n",
              "      <td>33.37</td>\n",
              "      <td>92.04</td>\n",
              "      <td>653.6</td>\n",
              "      <td>0.14190</td>\n",
              "      <td>0.15230</td>\n",
              "      <td>0.21770</td>\n",
              "      <td>0.09331</td>\n",
              "      <td>0.2829</td>\n",
              "      <td>0.08067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>18.01</td>\n",
              "      <td>20.56</td>\n",
              "      <td>118.40</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>0.10010</td>\n",
              "      <td>0.12890</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.07762</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>0.06077</td>\n",
              "      <td>0.7548</td>\n",
              "      <td>1.288</td>\n",
              "      <td>5.353</td>\n",
              "      <td>89.74</td>\n",
              "      <td>0.007997</td>\n",
              "      <td>0.02700</td>\n",
              "      <td>0.037370</td>\n",
              "      <td>0.016480</td>\n",
              "      <td>0.028970</td>\n",
              "      <td>0.003996</td>\n",
              "      <td>21.53</td>\n",
              "      <td>26.06</td>\n",
              "      <td>143.40</td>\n",
              "      <td>1426.0</td>\n",
              "      <td>0.13090</td>\n",
              "      <td>0.23270</td>\n",
              "      <td>0.25440</td>\n",
              "      <td>0.14890</td>\n",
              "      <td>0.3251</td>\n",
              "      <td>0.07625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "326        14.11         12.88  ...          0.2100                  0.07083\n",
              "13         15.85         23.95  ...          0.2809                  0.06287\n",
              "38         14.99         25.20  ...          0.1565                  0.05504\n",
              "135        12.77         22.47  ...          0.2829                  0.08067\n",
              "492        18.01         20.56  ...          0.3251                  0.07625\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HB1QMVQALeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "c83c231d-1880-40b5-c35d-d8264e263fb8"
      },
      "source": [
        "#normalize the data so that there no extreme values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit_transform(X_train)\n",
        "scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.54349129, -0.35505978, -0.57600826, ..., -0.5060577 ,\n",
              "         0.37102351, -0.16940445],\n",
              "       [ 0.10402502,  1.22422818,  0.16749935, ...,  0.09167617,\n",
              "         0.49156031,  0.94550795],\n",
              "       [ 2.67658983,  1.60056914,  2.84183771, ...,  2.4707784 ,\n",
              "         0.50947795,  0.16538812],\n",
              "       ...,\n",
              "       [ 0.21777789, -0.57907225,  0.12850123, ..., -0.5434258 ,\n",
              "        -0.58675541, -0.86290335],\n",
              "       [ 0.3927823 , -1.71033526,  0.45108349, ...,  1.0601327 ,\n",
              "         0.53879771,  0.87642377],\n",
              "       [ 0.25569551,  0.57907225,  0.24040887, ...,  0.25204759,\n",
              "         0.4524673 ,  0.42525092]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sGyLxOtJSPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(D-1,))) #D-1 because our initial data set shape had target column as part of the dataset\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSYDBQyMCjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWa0jE6PQiI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9288ebb6-3ce5-4be7-e19c-fed150a38603"
      },
      "source": [
        "#fit or train the model\n",
        "log_regression = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 63.3061 - accuracy: 0.3744 - val_loss: 56.9088 - val_accuracy: 0.3684\n",
            "Epoch 2/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 52.7148 - accuracy: 0.3744 - val_loss: 46.8200 - val_accuracy: 0.3684\n",
            "Epoch 3/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 42.4391 - accuracy: 0.3744 - val_loss: 36.4969 - val_accuracy: 0.3684\n",
            "Epoch 4/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 32.0320 - accuracy: 0.3744 - val_loss: 26.1708 - val_accuracy: 0.3684\n",
            "Epoch 5/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 21.6574 - accuracy: 0.3744 - val_loss: 15.9713 - val_accuracy: 0.3860\n",
            "Epoch 6/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 11.3369 - accuracy: 0.4020 - val_loss: 6.4501 - val_accuracy: 0.4854\n",
            "Epoch 7/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.0247 - accuracy: 0.6633 - val_loss: 0.9368 - val_accuracy: 0.8129\n",
            "Epoch 8/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6087 - accuracy: 0.8894 - val_loss: 0.6981 - val_accuracy: 0.9240\n",
            "Epoch 9/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.7812 - accuracy: 0.8995 - val_loss: 0.6992 - val_accuracy: 0.9240\n",
            "Epoch 10/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.6719 - accuracy: 0.8970 - val_loss: 0.6745 - val_accuracy: 0.9064\n",
            "Epoch 11/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.5897 - accuracy: 0.8819 - val_loss: 0.6925 - val_accuracy: 0.8889\n",
            "Epoch 12/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5782 - accuracy: 0.8894 - val_loss: 0.6961 - val_accuracy: 0.8830\n",
            "Epoch 13/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5720 - accuracy: 0.8869 - val_loss: 0.6831 - val_accuracy: 0.8889\n",
            "Epoch 14/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5732 - accuracy: 0.8819 - val_loss: 0.6823 - val_accuracy: 0.8889\n",
            "Epoch 15/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5788 - accuracy: 0.8869 - val_loss: 0.6907 - val_accuracy: 0.8830\n",
            "Epoch 16/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5710 - accuracy: 0.8869 - val_loss: 0.6818 - val_accuracy: 0.8889\n",
            "Epoch 17/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.8844 - val_loss: 0.6806 - val_accuracy: 0.8889\n",
            "Epoch 18/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5805 - accuracy: 0.8869 - val_loss: 0.6771 - val_accuracy: 0.8889\n",
            "Epoch 19/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.8844 - val_loss: 0.6870 - val_accuracy: 0.8830\n",
            "Epoch 20/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5681 - accuracy: 0.8844 - val_loss: 0.6867 - val_accuracy: 0.8830\n",
            "Epoch 21/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5683 - accuracy: 0.8894 - val_loss: 0.6820 - val_accuracy: 0.8830\n",
            "Epoch 22/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5658 - accuracy: 0.8844 - val_loss: 0.6724 - val_accuracy: 0.8947\n",
            "Epoch 23/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5640 - accuracy: 0.8869 - val_loss: 0.6806 - val_accuracy: 0.8830\n",
            "Epoch 24/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5610 - accuracy: 0.8819 - val_loss: 0.6792 - val_accuracy: 0.8830\n",
            "Epoch 25/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5644 - accuracy: 0.8844 - val_loss: 0.6785 - val_accuracy: 0.8830\n",
            "Epoch 26/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5592 - accuracy: 0.8844 - val_loss: 0.6793 - val_accuracy: 0.8830\n",
            "Epoch 27/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5575 - accuracy: 0.8844 - val_loss: 0.6780 - val_accuracy: 0.8830\n",
            "Epoch 28/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5599 - accuracy: 0.8844 - val_loss: 0.6719 - val_accuracy: 0.8830\n",
            "Epoch 29/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5561 - accuracy: 0.8794 - val_loss: 0.6789 - val_accuracy: 0.8830\n",
            "Epoch 30/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5635 - accuracy: 0.8819 - val_loss: 0.6788 - val_accuracy: 0.8830\n",
            "Epoch 31/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5545 - accuracy: 0.8869 - val_loss: 0.6681 - val_accuracy: 0.8830\n",
            "Epoch 32/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5556 - accuracy: 0.8869 - val_loss: 0.6748 - val_accuracy: 0.8830\n",
            "Epoch 33/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.8819 - val_loss: 0.6706 - val_accuracy: 0.8830\n",
            "Epoch 34/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5505 - accuracy: 0.8844 - val_loss: 0.6661 - val_accuracy: 0.8830\n",
            "Epoch 35/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5509 - accuracy: 0.8844 - val_loss: 0.6738 - val_accuracy: 0.8830\n",
            "Epoch 36/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.5460 - accuracy: 0.8920 - val_loss: 0.6695 - val_accuracy: 0.8830\n",
            "Epoch 37/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.5620 - accuracy: 0.8869 - val_loss: 0.6557 - val_accuracy: 0.9064\n",
            "Epoch 38/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.8869 - val_loss: 0.6723 - val_accuracy: 0.8830\n",
            "Epoch 39/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.8844 - val_loss: 0.6634 - val_accuracy: 0.8830\n",
            "Epoch 40/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5440 - accuracy: 0.8869 - val_loss: 0.6650 - val_accuracy: 0.8830\n",
            "Epoch 41/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 0.8894 - val_loss: 0.6556 - val_accuracy: 0.8889\n",
            "Epoch 42/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.8869 - val_loss: 0.6630 - val_accuracy: 0.8830\n",
            "Epoch 43/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5365 - accuracy: 0.8844 - val_loss: 0.6652 - val_accuracy: 0.8830\n",
            "Epoch 44/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5379 - accuracy: 0.8844 - val_loss: 0.6576 - val_accuracy: 0.8830\n",
            "Epoch 45/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5493 - accuracy: 0.8945 - val_loss: 0.6608 - val_accuracy: 0.8830\n",
            "Epoch 46/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.8894 - val_loss: 0.6502 - val_accuracy: 0.8889\n",
            "Epoch 47/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.8869 - val_loss: 0.6527 - val_accuracy: 0.8889\n",
            "Epoch 48/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5271 - accuracy: 0.8844 - val_loss: 0.6573 - val_accuracy: 0.8830\n",
            "Epoch 49/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.8869 - val_loss: 0.6550 - val_accuracy: 0.8830\n",
            "Epoch 50/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5250 - accuracy: 0.8970 - val_loss: 0.6433 - val_accuracy: 0.9006\n",
            "Epoch 51/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5227 - accuracy: 0.8945 - val_loss: 0.6532 - val_accuracy: 0.8830\n",
            "Epoch 52/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.5324 - accuracy: 0.8894 - val_loss: 0.6538 - val_accuracy: 0.8830\n",
            "Epoch 53/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8945 - val_loss: 0.6386 - val_accuracy: 0.9006\n",
            "Epoch 54/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5168 - accuracy: 0.8970 - val_loss: 0.6516 - val_accuracy: 0.8830\n",
            "Epoch 55/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.8920 - val_loss: 0.6532 - val_accuracy: 0.8830\n",
            "Epoch 56/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5453 - accuracy: 0.8945 - val_loss: 0.6329 - val_accuracy: 0.9006\n",
            "Epoch 57/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.8970 - val_loss: 0.6496 - val_accuracy: 0.8830\n",
            "Epoch 58/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5257 - accuracy: 0.8920 - val_loss: 0.6481 - val_accuracy: 0.8830\n",
            "Epoch 59/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.8995 - val_loss: 0.6517 - val_accuracy: 0.8830\n",
            "Epoch 60/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5088 - accuracy: 0.8920 - val_loss: 0.6329 - val_accuracy: 0.9006\n",
            "Epoch 61/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.8970 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 62/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5088 - accuracy: 0.9020 - val_loss: 0.6410 - val_accuracy: 0.8830\n",
            "Epoch 63/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.5167 - accuracy: 0.8995 - val_loss: 0.6305 - val_accuracy: 0.9006\n",
            "Epoch 64/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.5108 - accuracy: 0.8970 - val_loss: 0.6358 - val_accuracy: 0.8889\n",
            "Epoch 65/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.8869 - val_loss: 0.6363 - val_accuracy: 0.8830\n",
            "Epoch 66/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.8920 - val_loss: 0.6295 - val_accuracy: 0.8889\n",
            "Epoch 67/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.8894 - val_loss: 0.6361 - val_accuracy: 0.8830\n",
            "Epoch 68/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4944 - accuracy: 0.8970 - val_loss: 0.6204 - val_accuracy: 0.9006\n",
            "Epoch 69/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8920 - val_loss: 0.6296 - val_accuracy: 0.8889\n",
            "Epoch 70/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.8945 - val_loss: 0.6196 - val_accuracy: 0.9006\n",
            "Epoch 71/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8995 - val_loss: 0.6202 - val_accuracy: 0.9006\n",
            "Epoch 72/75\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5002 - accuracy: 0.8995 - val_loss: 0.6383 - val_accuracy: 0.8830\n",
            "Epoch 73/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.4885 - accuracy: 0.9020 - val_loss: 0.6179 - val_accuracy: 0.9006\n",
            "Epoch 74/75\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.4891 - accuracy: 0.8995 - val_loss: 0.6139 - val_accuracy: 0.9006\n",
            "Epoch 75/75\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.8995 - val_loss: 0.6172 - val_accuracy: 0.9006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3FZ_pXGRJbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "102b3c67-baf2-491e-f5b2-fbdd10b21afe"
      },
      "source": [
        "#evaluate the model\n",
        "print(\"Train score : \", model.evaluate(X_train, y_train))\n",
        "print(\"Test score : \", model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.9020\n",
            "Train score :  [0.4805312156677246, 0.9020100235939026]\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.9006\n",
            "Test score :  [0.6172025799751282, 0.9005848169326782]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MV9lK9XRpo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dd5aff09-7ffa-4e31-b252-544e16efe63b"
      },
      "source": [
        "#plot the loss data during training\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(log_regression.history['loss'], label='loss')\n",
        "plt.plot(log_regression.history['val_loss'], label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f740a4e9e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EopmoP_JUMOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fc44b667-bfea-4be7-f34f-851cdc4bf76e"
      },
      "source": [
        "plt.plot(log_regression.history['accuracy'], label='acuracy')\n",
        "plt.plot(log_regression.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f740a4e6ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrbNeRcTUeFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b66da8f3-cd12-404f-fab9-bc2116c5655d"
      },
      "source": [
        "#predict any data using the model\n",
        "y_predict = model.predict(X_test)\n",
        "y_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99542415e-01],\n",
              "       [9.97800767e-01],\n",
              "       [1.18018608e-08],\n",
              "       [9.54926670e-01],\n",
              "       [1.17889129e-10],\n",
              "       [3.52418761e-10],\n",
              "       [9.80058084e-35],\n",
              "       [9.99926209e-01],\n",
              "       [9.97431517e-01],\n",
              "       [3.22193778e-15],\n",
              "       [0.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.93683535e-01],\n",
              "       [9.99945879e-01],\n",
              "       [9.99104738e-01],\n",
              "       [9.97077346e-01],\n",
              "       [8.86989236e-01],\n",
              "       [9.99987364e-01],\n",
              "       [2.19779173e-22],\n",
              "       [9.78000522e-01],\n",
              "       [9.99958813e-01],\n",
              "       [9.01588678e-01],\n",
              "       [3.01778400e-15],\n",
              "       [9.99698639e-01],\n",
              "       [9.99997139e-01],\n",
              "       [5.04105687e-01],\n",
              "       [9.99960780e-01],\n",
              "       [9.99873400e-01],\n",
              "       [6.04279160e-01],\n",
              "       [2.63243914e-04],\n",
              "       [1.47193670e-04],\n",
              "       [7.58945617e-08],\n",
              "       [3.82365025e-38],\n",
              "       [9.99999523e-01],\n",
              "       [9.94980693e-01],\n",
              "       [9.99859333e-01],\n",
              "       [9.99952435e-01],\n",
              "       [9.75880623e-01],\n",
              "       [7.56543219e-01],\n",
              "       [9.99997675e-01],\n",
              "       [9.99941468e-01],\n",
              "       [9.99702334e-01],\n",
              "       [9.99992728e-01],\n",
              "       [3.02720070e-03],\n",
              "       [3.12298536e-04],\n",
              "       [9.99918461e-01],\n",
              "       [9.99999642e-01],\n",
              "       [9.99953151e-01],\n",
              "       [9.99959886e-01],\n",
              "       [9.99974847e-01],\n",
              "       [1.02269730e-08],\n",
              "       [9.97778058e-01],\n",
              "       [3.99364673e-11],\n",
              "       [9.99999404e-01],\n",
              "       [6.29826413e-09],\n",
              "       [1.66549482e-19],\n",
              "       [9.99678135e-01],\n",
              "       [2.98673144e-18],\n",
              "       [9.68641162e-01],\n",
              "       [9.99900579e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.60951117e-07],\n",
              "       [4.76111425e-12],\n",
              "       [9.99996424e-01],\n",
              "       [9.55443919e-01],\n",
              "       [9.50370312e-01],\n",
              "       [9.99315321e-01],\n",
              "       [1.42024308e-01],\n",
              "       [9.98703718e-01],\n",
              "       [4.65081330e-20],\n",
              "       [8.85525951e-05],\n",
              "       [0.00000000e+00],\n",
              "       [9.86844003e-02],\n",
              "       [9.99663889e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99998927e-01],\n",
              "       [2.17134728e-13],\n",
              "       [9.77625728e-01],\n",
              "       [9.99912500e-01],\n",
              "       [9.99673486e-01],\n",
              "       [9.99959350e-01],\n",
              "       [3.31872119e-26],\n",
              "       [9.99791861e-01],\n",
              "       [9.97014761e-01],\n",
              "       [9.99823689e-01],\n",
              "       [1.06632775e-07],\n",
              "       [9.99975443e-01],\n",
              "       [1.01092541e-19],\n",
              "       [1.17510751e-06],\n",
              "       [0.00000000e+00],\n",
              "       [7.88543416e-16],\n",
              "       [1.97656416e-08],\n",
              "       [8.57845902e-01],\n",
              "       [9.88606393e-01],\n",
              "       [9.99925017e-01],\n",
              "       [0.00000000e+00],\n",
              "       [4.88042831e-04],\n",
              "       [9.99999404e-01],\n",
              "       [9.99998927e-01],\n",
              "       [9.96686935e-01],\n",
              "       [8.91584895e-18],\n",
              "       [9.99975979e-01],\n",
              "       [1.88447535e-02],\n",
              "       [5.18343031e-01],\n",
              "       [9.99593496e-01],\n",
              "       [2.05551586e-13],\n",
              "       [9.99908805e-01],\n",
              "       [9.99995232e-01],\n",
              "       [9.95600939e-01],\n",
              "       [1.16635941e-18],\n",
              "       [9.99951899e-01],\n",
              "       [9.94193316e-01],\n",
              "       [9.99993384e-01],\n",
              "       [4.82078638e-15],\n",
              "       [9.69105244e-01],\n",
              "       [0.00000000e+00],\n",
              "       [9.99271750e-01],\n",
              "       [1.65183544e-02],\n",
              "       [9.99997258e-01],\n",
              "       [9.99770522e-01],\n",
              "       [9.99988675e-01],\n",
              "       [9.46611166e-04],\n",
              "       [9.99967694e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.57923174e-01],\n",
              "       [9.99990702e-01],\n",
              "       [9.90744233e-01],\n",
              "       [9.98947203e-01],\n",
              "       [9.98241067e-01],\n",
              "       [9.99999702e-01],\n",
              "       [3.58519493e-24],\n",
              "       [2.49742299e-01],\n",
              "       [8.71974647e-01],\n",
              "       [9.99880373e-01],\n",
              "       [9.99930859e-01],\n",
              "       [7.19650924e-01],\n",
              "       [9.66785312e-01],\n",
              "       [1.21090193e-09],\n",
              "       [0.00000000e+00],\n",
              "       [9.99927104e-01],\n",
              "       [1.27439581e-18],\n",
              "       [9.94585931e-01],\n",
              "       [0.00000000e+00],\n",
              "       [9.99967933e-01],\n",
              "       [6.75526322e-27],\n",
              "       [9.16688979e-01],\n",
              "       [2.13513715e-07],\n",
              "       [7.09354884e-13],\n",
              "       [1.30504370e-04],\n",
              "       [8.14184284e-28],\n",
              "       [9.99786735e-01],\n",
              "       [9.99718189e-01],\n",
              "       [9.99925077e-01],\n",
              "       [3.71308914e-07],\n",
              "       [6.27876151e-09],\n",
              "       [3.53189867e-18],\n",
              "       [9.54352736e-01],\n",
              "       [9.95842814e-01],\n",
              "       [9.99981284e-01],\n",
              "       [9.77105618e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99954402e-01],\n",
              "       [5.45606214e-16],\n",
              "       [0.00000000e+00],\n",
              "       [9.99845922e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.26959750e-17],\n",
              "       [3.75265665e-15],\n",
              "       [9.96910512e-01],\n",
              "       [6.11341164e-13],\n",
              "       [8.76435518e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXoQuGxlVheX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a31a36c2-fd54-4ee2-98a2-aebeeb1d8989"
      },
      "source": [
        "#calculate accuracy manually\n",
        "import numpy as np\n",
        "y_predict.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(171, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Oei9A-V5ke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d416cad-d066-408d-a77e-2b431ad2137e"
      },
      "source": [
        "y_predict_vector = np.round(y_predict).flatten()\n",
        "y_predict_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(171,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKdQWaJ9WEJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a320387c-246b-4628-dfc5-80edaa08719b"
      },
      "source": [
        "print(\"Accuracy is : \", np.mean(y_predict_vector == y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is :  0.9005847953216374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcEOHCCdWnTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "11d09336-d5d1-43b4-bb88-00e49951591f"
      },
      "source": [
        "#show classification report from sklearn\n",
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(y_test, y_predict_vector, target_names=cancer_data.target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.86      0.87      0.87        63\n",
            "      benign       0.93      0.92      0.92       108\n",
            "\n",
            "    accuracy                           0.90       171\n",
            "   macro avg       0.89      0.89      0.89       171\n",
            "weighted avg       0.90      0.90      0.90       171\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mJVgiLDXWW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1cf191d8-4e08-4db1-c6c5-41f86c3291fa"
      },
      "source": [
        "#save the data\n",
        "model.save('log_regression_linear.mod')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: log_regression_linear.mod/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmlb2it8YmFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d35d89e0-6b47-4faa-c0a5-45b51eaeba6d"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log_regression_linear.mod  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsfgzaL0YpIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "39bd3810-6454-401d-8d62-83cabf28a8b5"
      },
      "source": [
        "#load data and check if it works\n",
        "new_model = tf.keras.models.load_model('log_regression_linear.mod')\n",
        "print(new_model.layers)\n",
        "new_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.core.Dense object at 0x7f740a615da0>]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.9006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6172025799751282, 0.9005848169326782]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQ_jLeHZHso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "be12f9ac-1705-4706-aa44-b07b5229faca"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('log_regression_linear.mod')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1fdcd71e-3dad-439a-a378-06b81310a08a\", \"log_regression_linear.mod\", 4096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}